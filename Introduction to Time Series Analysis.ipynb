{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Time Series Analysis is a statistical method used to analyze and understand data points collected over time. It involves examining patterns, trends and dependencies within the data to make predictions or uncover insights about the underlying process generating the data.<br>\n",
    "The data is considered in three types:<br>\n",
    "1. **Time Series Data** - a set of observations on the values that a variable takes at different times.<br>\n",
    "2. **Cross-sectional Data** - data of one or more variables, collected at the same point.<br>\n",
    "3. **Pooled Data** - a combination of time series data and cross-sectional data.\n",
    "\n",
    "With the help of Time Series one can prepare numerous time-based analyses and results.\n",
    "- **Forecasting** - Predicting any value for the future.\n",
    "- **Segmentation** - Grouping similar items together.\n",
    "- **Classification** - Classifying a set of items into given classes.\n",
    "- **Descriptive analysis** -Analysis of a given dataset to find out what is there in it.\n",
    "- **Intervention analysis**: Effect of changing a given variable on the outcome.\n",
    "\n",
    "### Components of Time Series Analysis\n",
    "- **Trend**- there is no fixed interval and any divergence within the given dataset is a continuous timeline. The trend would be Negative or Positive or Null Trend\n",
    "- **Seasonality** - In which regular or fixed interval shifts within the dataset in a continuous timeline. Would be bell curve or saw tooth.\n",
    "- **Cyclical**- there is no fixed interval, uncertainty in movement and its pattern\n",
    "- **Irregularity** - Unexpected situations/events/scenarios and spikes in a short time span.\n",
    "\n",
    "### Applications of Times Series Models\n",
    "- Economic Forecasting\n",
    "- Sales Forecasting\n",
    "- Budgetary Analysis\n",
    "- Stock Market Analysis\n",
    "- Yield Projections\n",
    "- Process and Quality Control\n",
    "- Weather Forecating\n",
    "- Census Analysis\n",
    "\n",
    "### Limitations of Time Series Analysis\n",
    "- The missing values are not supported by TSA.\n",
    "- The data points must be linear in their relationship.\n",
    "- Data transormations are mandatory, so they are abit expensive.\n",
    "- Models mostly work on Uni-variate data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of Terms and Techniques\n",
    "\n",
    "- ## Dependence\n",
    "Dependence refers to the relationship or correlation between observations at different time points within the series. It indicates whether the value of a particular observation is influenced by or dependent on the values of previous or future observations.<br>\n",
    "\n",
    "*There are different types of dependence that can be observed in TSA:*<br>\n",
    "1. **Serial Dependence (Autocorrelation)** <br>\n",
    "It measures the relationship between observations at different lags within the same time series. It quantifies the degree of similarity or dependence between observations and its lagged values.<br>\n",
    "Autocorrelation is often used to identify patterns, trends and seasonality in time series data. Positive autocorrelation indicates that high values are follwed by high values, and low values are followed by low values, while negative autocorrelation indicates an inverse relationship.<br><br>\n",
    "\n",
    "2. **Cross-Correlation** <br>\n",
    "It measures the rellationship between two different time series. It helps determine if changes in one series are related to changes in another series, and the degree of time lag between them.<br>\n",
    "Cross-correlation analysis is commonly used to investigate the cause-and-effect relationships or dependencies between variables in different domains such as finance, economics and engineering.<br><br>\n",
    "\n",
    "3. **Dependence on Exogenous Variables** <br>\n",
    "TSA can also consider the dependence of a sries on exogenous variables, whih are external factors that may influence the behavior of the time series. For example, in sales forecasting, the sales data may depend not only on pervious sales but also on factors like advertising expenditure, holidays or economic indicators.\n",
    "\n",
    "- ## Stationarity\n",
    "A time series is said to be stationary if its statistical properties, such as mean, variance and covariance remain constant over time. In simpler terms, a stationary time series has a stable and predictable  behavior.<br><br>\n",
    "\n",
    "*There are three main components of stationarity:*<br>\n",
    "1. **Constant Mean** <br>\n",
    "The mean of the time series remains constant or does not exhibit a trend over time. This implies that the average value of the series does not systematically increase or decrease as time progresses.<br>\n",
    "\n",
    "2. **Constant Variance** <br>\n",
    "The variance of the time series remains constant over time. It indicates that the spread or dispersion of the data points around the mean remains consistent throughout the series.<br>\n",
    "\n",
    "3. **Constant Covariance** <br>\n",
    "The covariance between two observations at different time points, often referred to as lagged observations, remains constant. This property is known as the autocovariance or autocorrelation structure of the series.<br><br>\n",
    "\n",
    "Stationarity is important because many TSA techniques, such as ARIMA models assume or require the data to be stationary.\n",
    "\n",
    "#### Methods to Check Stationarity\n",
    "This is done using statistical tests:<br>\n",
    "\n",
    "1. *Augmented Dickey-Fuller (ADF) Test or Unit Root Test*<br>\n",
    "The ADF test is the most popular statistical test. It is done with the following assumptions:<br>\n",
    "- Null Hypothesis (H0): Series is non-stationary\n",
    "- Alternate Hypothesis (HA): Series is stationary\n",
    "        <br>- p-value >0.05 Fail to reject (H0)\n",
    "        <br>- p-value <= 0.05 Accept (H1)\n",
    "\n",
    "2. *Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Test* <br>\n",
    "These tests are used for testing a NULL Hypothesis (HO) that will perceive the time series as stationary around a deterministic trend against the alternative of a unit root. Since TSA is looking for Stationary Data for its further analysis, we have to ensure that the dataset is stationary.\n",
    "\n",
    "#### Converting Non-Stationary into Stationary\n",
    "There are three methods available for this conversion - detrending, differencing and transformation. <br>\n",
    "\n",
    "- **Detrending**\n",
    "It involves removing the trend effects from the given dataset and showing only the differences in values from the trend. It always allows cyclical patterns to be identified.\n",
    "\n",
    "![Alt text](image-1.png)\n",
    "\n",
    "\n",
    "- **Differencing**\n",
    "A technique in TSA to transform a non-stationary series into a stationary one.\n",
    "\n",
    "![Alt text](image.png)\n",
    "\n",
    "- **Transformation**\n",
    "This includes three different methods they are Power Transform, Square Root, and Log Transfer. The most commonly used one is Log Transfer.\n",
    "\n",
    "\n",
    "- ## Specification\n",
    "The process of selecting and defining appropriate model for analysing and forecasting a given time series. It involves determining the structure, parameters and assumptions of the model based on the characteristics and properties of the data.<br><br>\n",
    "\n",
    "*Components of specification of a time series model.* <br>\n",
    "1. **Model Type** <br>\n",
    "This decision depends on the characteristics observed in the data, such as trend, seasonality, and dependence. Common model types include autoregressive (AR) models, moving average (MA) models, autoregressive integrated moving average (ARIMA) models, seasonal ARIMA (SARIMA) models, and exponential smoothing models.<br>\n",
    "\n",
    "2. **Order and Lag Selection** <br>\n",
    "Once the model type is chosen, the next step is to determine the appropriate order or lags for the model. This involves selecting the number of lagged terms to include in the model equation. In AR models, the order represents the number of lagged terms of the dependent variable. In MA models, it represents the number of lagged error terms. For ARIMA or SARIMA models, both autoregressive and moving average orders need to be specified.<br>\n",
    "\n",
    "3. **Seasonality** <br>\n",
    "If the time series exhibits seasonal patterns, the specification should include the seasonal component. This involves determining the seasonal period (e.g., daily, monthly, quarterly) and the appropriate seasonal order or lags for the model.<br>\n",
    "\n",
    "4. **Exogenous Variable** <br>\n",
    "If there are additional variables that are believed to influence the behavior of the time series, such as economic indicators or external factors, they can be included as exogenous variables in the model specification. The selection and inclusion of these variables depend on their relevance and availability.<br>\n",
    "\n",
    "5. **Error Distribution** <br>\n",
    "It determines the assumptions about the distribution of the model residuals or errors. Common distributions used include Gaussian (normal), Student's t-distribution, or other distribution families.<br>\n",
    "\n",
    "6. **Parameter Estimation** <br>\n",
    "Estimate the model parameters using various estimation techniques such as maximum likelihood estimation (MLE) or least squares estimation (LSE). The estimation process involves fitting the model to the historical data to obtain the parameter estimates that best capture the underlying patterns and dependencies in the series.<br>\n",
    "\n",
    "- ## Exponential Smoothing\n",
    "This is a widely used technique in TSA for forecating future values based on the historical data. It is a simple and effective method that assigns exponentially decreasing weights to past observations, with more recent observations given higeher weights.<br>\n",
    "\n",
    "*Commonly used variations of exponential smoothing models:*  <br>\n",
    "#### 1. Simple Exponential Smoothing (SES) \n",
    "This method is suitable for data with no clear trend or seasonal pattern.<br><br>\n",
    "**Example: Oil Production <br>**\n",
    "The graph represents oil production in Saudi Arabia from 1996 to 2013\n",
    "\n",
    "![Alt text](image-2.png)\n",
    "\n",
    "Using the **naive method**, all forecasts for the future are equal to the last observed value of the series\n",
    "\n",
    "![Alt text](image-3.png)\n",
    "\n",
    "for *h* = 1,2 ... hence the naive method assumes that the most recent observation is the only important one, and all previous observations provide no information for the future. This can be thought of as a weighted average where all of the weight is given to the last observation.<br>\n",
    "Using the **average method**, all future forecasts are equal to a simple average of the observed data.\n",
    "\n",
    "![Alt text](image-4.png)\n",
    "\n",
    "Hence, the **average method** assumes that all observations are of equal importance, and gives them equal weights when generating forecasts.<br>\n",
    "We often want something between these two extremes. For example, it may be sensible to attach larger weights to more recent observations that to observations from the distant past. This is exactly the concept behind simple exponential smoothing. forecasts are calculated using weighted averages, where the weights decrease exponentially as observations come further in the past - the smallerst weights are assosiated with the oldest observations.\n",
    "\n",
    "![Alt text](image-5.png)\n",
    "\n",
    "where *0≤α≤1* is the smoothing parameter. The one-step-ahead forecast for time *T+1* is a weighted average of all the observations in the series *y1, .... ,yT*. The rate at which the weights decreases is controlled by the parameter *α*. <br>\n",
    "The table below shows the weights attached to observations for four different values of α when forecasting using simple exponential smoothing. \n",
    "\n",
    "![Alt text](image-6.png)\n",
    "\n",
    "For any α between 0 and 1, the weights attached to the observations decrease exponentially as we go back in time, hence the name “exponential smoothing”. If *α* is small (i.e., close to 0), more weight is given to observations from the more distant past. If *α* islarge (i.e., close to 1), more weight is given to the more recent observations. For the extreme case where  \n",
    "*α=1* ,*yT+1|T= yT*, and the forecasts are equal to the naïve forecasts.<br>\n",
    "We present two equivalent forms of simple exponential smoothing, each of which leads to the forecast Equation.\n",
    "\n",
    "![Alt text](image-7.png)\n",
    "\n",
    "where the level,ℓt. <br>\n",
    "\n",
    "Use of simple exponentional smoothing is applied to forecast oil production in Saudi Arabia<br>\n",
    "\n",
    "![Alt text](image-8.png)\n",
    "\n",
    "Table indicating Forecasting the total oil production in millions of tonnes for Saudi Arabia using simple exponential smoothing.\n",
    "\n",
    "![Alt text](image-9.png)\n",
    "\n",
    "Forecast plot:\n",
    "\n",
    "![Alt text](image-10.png)\n",
    "\n",
    "The forecasts for the period 2014–2018 are plotted above. Also plotted are one-step-ahead fitted values alongside the data over the period 1996–2013.\n",
    "#### 2. Holt's Linear Exponential Smoothing\n",
    "Holt (1957) extended simple exponential smoothing to allow the forecasting of data with a trend.<br>\n",
    "This method involves a forecast equation and two smoothing equations (one for the level and one for the trend)\n",
    "\n",
    "![Alt text](image-11.png)\n",
    "\n",
    "Where <br>\n",
    "ℓt - estimate of the level of the series at time *t* <br>\n",
    "*b*t -estimate of the trend (slope) of the series at time *t* <br>\n",
    "*α* -  smoothing parameter for the level <br>\n",
    "*β*∗ - smoothing parameter for the trend <br>\n",
    "\n",
    "**Example: Air passengers <br>**\n",
    "\n",
    "![Alt text](image-12.png)\n",
    "\n",
    "The table below demonstrates the application of Holt's method to annual passenger numbers for Australian airlines. The smoothing parameters, *α* and *β*∗, ant the inital values ℓ0 and *b*0 are stimated by minimising the SSE for the one-step training errors.<br>\n",
    "*α* = 0.8321 and *β*∗ =0.0001 <br>\n",
    "\n",
    "![Alt text](image-13.png)\n",
    " \n",
    " \n",
    "#### 3. Holt-Winters Exponential Smoothing\n",
    "Holt(1957) and Winters(1960) extended Holt's method to capture seasonality. The Holt-Winters seasonal method comprises the forecast equation and three smoothing equatons - one for the level *ℓ*t, one for the trend *b*t, and one for the seasonal components *s*t, with corresponding smoothing parameters *α*, *β*∗ and *γ*. <br>\n",
    "We use *m* to denote the frequency of the seasonality, i.e., the number of seasons in a year. For example for quarterly data *m* = 4, and for monthly data *m* = 12.\n",
    "<br><br>\n",
    "There are two variations in this method <br>\n",
    "\n",
    "1. **Holt-Winters’ additive method** <br>\n",
    "This method is preferred when the seasonal variations are roughly constant throughout the series. The seasonal component is expressed in absolute terms in the scale of the observed series, and in the level equation the series is seasonally adjusted by subtracting the seasonal component. Within each year, the seasonal compomemt witll add up to approximately zero. <br>\n",
    "\n",
    "\n",
    "2. **Holt-Winters’ multiplicative method** <br>\n",
    "This method is preferred when the seasonal variations are changing proportional to the level of the series. The seasonal seasonal component is expressed in relative terms (percentages), and the series is seasonally adjusted by dividing through by the seasonal component. Within each year, the seasonal component will sum up to approximately m*. <br>\n",
    "\n",
    "- ## Decompostion\n",
    "A technique in TSA to understand and model the underlying components of a time series. It involves separating a time series into its constituent parts: trend, seasonal effects and noise(or residuals).<br>\n",
    "Decomposition helps in identifying patterns, trends ad cycles within the data, which can aid in forecasting and understanding the time series behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
